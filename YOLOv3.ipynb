{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtFjWcJkd/o2EsXsw/u+tH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serepina/Human_Detector_Comparison/blob/main/YOLOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLYA90bFmnAL"
      },
      "source": [
        "**YOLOv3 OpenCV를 사용하여서 Video 결과 얻기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpN2tTaVpXx_",
        "outputId": "36c8ba8e-7c43-4bdb-e771-f6a6e2869ef2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLDW3N3ppnNT",
        "outputId": "90b64d05-4f93-48fa-a86e-988a13e8724a"
      },
      "source": [
        "!python -m pip install --user opencv-contrib-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "B8OcKqTXmlUC",
        "outputId": "ab31c5a4-7138-40c1-b6a1-299a8423a49e"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import os\r\n",
        "import time\r\n",
        "\r\n",
        "cv2.face.LBPHFaceRecognizer_create() \r\n",
        "\r\n",
        "classes = [\"person\", \"bicycle\", \"car\", \"motorcycle\",\r\n",
        "            \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\",\r\n",
        "            \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\",\r\n",
        "            \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\r\n",
        "            \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\",\r\n",
        "            \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\r\n",
        "            \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\",\r\n",
        "            \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\r\n",
        "            \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\",\r\n",
        "            \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\",\r\n",
        "            \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\r\n",
        "            \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\" ]\r\n",
        "\r\n",
        "weightsPath = os.path.sep.join([os.path.abspath(\"/content/drive/MyDrive/Colab Notebooks/YOLOv3\"), \"yolov4.weights\"])\r\n",
        "configPath = os.path.sep.join([os.path.abspath(\"/content/drive/MyDrive/Colab Notebooks/YOLOv3\"), \"yolov4-csp.cfg\"])\r\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\r\n",
        "\r\n",
        "layer_names = net.getLayerNames()\r\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\r\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\r\n",
        "\r\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Colab Notebooks/test1.mp4')\r\n",
        "\r\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\r\n",
        "width  = int(cap.get(3)) # float\r\n",
        "height = int(cap.get(4)) # float\r\n",
        "\r\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V') #codec\r\n",
        "vout = cv2.VideoWriter('/content/drive/MyDrive/Colab Notebooks/video4_1.mp4', fourcc, fps, (width,height))\r\n",
        "\r\n",
        "start = time.time()  # 시작 시간 저장\r\n",
        "while (cap.isOpened()):\r\n",
        "  ret, img = cap.read()\r\n",
        "\r\n",
        "  if ret:\r\n",
        "    height, width, channels = img.shape\r\n",
        "\r\n",
        "    image = img\r\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\r\n",
        "    net.setInput(blob)\r\n",
        "    outs = net.forward(output_layers)\r\n",
        "\r\n",
        "    class_ids = []\r\n",
        "    confidences = []\r\n",
        "    boxes = []\r\n",
        "\r\n",
        "    for out in outs:\r\n",
        "        for detection in out:\r\n",
        "            scores = detection[5:]\r\n",
        "            class_id = np.argmax(scores)\r\n",
        "            confidence = scores[class_id]\r\n",
        "            if confidence > 0.1:\r\n",
        "                # Object detected\r\n",
        "                center_x = int(detection[0] * width)\r\n",
        "                center_y = int(detection[1] * height)\r\n",
        "                w = int(detection[2] * width)\r\n",
        "                h = int(detection[3] * height)\r\n",
        "\r\n",
        "                # Rectangle coordinates\r\n",
        "                x = int(center_x - w / 2)\r\n",
        "                y = int(center_y - h / 2)\r\n",
        "\r\n",
        "                boxes.append([x, y, w, h])\r\n",
        "                confidences.append(float(confidence))\r\n",
        "                class_ids.append(class_id)\r\n",
        "\r\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.4)\r\n",
        "\r\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\r\n",
        "    for i in range(len(boxes)):\r\n",
        "        if i in indexes:\r\n",
        "            x, y, w, h = boxes[i]\r\n",
        "            label = str(classes[class_ids[i]])\r\n",
        "            color = colors[i]\r\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\r\n",
        "            cv2.putText(img, label, (x, y - 10), font, 1, color, 2)\r\n",
        "            #print(label,confidences[i],x,y,w,h)\r\n",
        "\r\n",
        "    vout.write(image)\r\n",
        "\r\n",
        "  else:\r\n",
        "    print(\"time :\", time.time() - start)\r\n",
        "    break\r\n",
        "\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-00d9b727f645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mweightsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/YOLOv3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yolov4.weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mconfigPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/YOLOv3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yolov4-csp.cfg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLayerNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/dnn/src/darknet/darknet_io.cpp:554: error: (-212:Parsing error) Unsupported activation: mish in function 'ReadDarknetFromCfgStream'\n"
          ]
        }
      ]
    }
  ]
}